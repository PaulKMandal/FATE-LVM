{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Federated GPT-2 Tuning with Parameter Efficient methods in FATE-LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate how to efficiently train federated large language models using the FATE-LLM framework. In FATE-LLM, we introduce the \"pellm\"(Parameter Efficient Large Language Model) module, specifically designed for federated learning with large language models. We enable the implementation of parameter-efficient methods in federated learning, reducing communication overhead while maintaining model performance. In this tutorial we particularlly focus on GPT-2, and we will also emphasize the use of the Adapter mechanism for fine-tuning GPT-2, which enables us to effectively reduce communication volume and improve overall efficiency.\n",
    "\n",
    "By following this tutorial, you will learn how to leverage the FATE-LLM framework to rapidly fine-tune federated large language models, such as GPT-2, with ease and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2\n",
    "\n",
    "GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset of 8 million web pages. GPT-2 is trained with a causal language modeling (CLM) objective, conditioning on a left-to-right context window of 1024 tokens. In this tutorial, we will use GPT2, you can download the pretrained model from [here](https://huggingface.co/gpt2) (We choose the smallest version for this tutorial), or let the program automatically download it when you use it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: IMDB Sentimental\n",
    "\n",
    "In this section, we will introduce the process of preparing the IMDB dataset for use in our federated learning task. We use our tokenizer dataset(based on HuggingFace tokenizer) to preprocess the text data.\n",
    "\n",
    "About IMDB Sentimental Dataset:\n",
    "\n",
    "This is an binary classification dataset, you can download our processed dataset from here: \n",
    "- https://webank-ai-1251170195.cos.ap-guangzhou.myqcloud.com/fate/examples/data/IMDB.csv\n",
    "and place it in the examples/data folder. \n",
    "\n",
    "The orgin data is from: \n",
    "- https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "### Check Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details of FATE-LLM dataset setting, we recommend that you read through these tutorials first: [NN Dataset Customization](https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-your-Dataset.ipynb), [Some Built-In Dataset](https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/pipeline/nn_tutorial/Introduce-Built-In-Dataset.ipynb),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PELLM Model with Adapter\n",
    "\n",
    "In this section, we will guide you through the process of building a parameter-efficient language model using the FATE-LLM framework. We will focus on the implementation of the PELLM model and the integration of the Adapter mechanism, which enables efficient fine-tuning and reduces communication overhead in federated learning settings. Take GPT-2 as example you will learn how to leverage the FATE-LLM framework to rapidly develop and deploy a parameter-efficient language model using FATE-LLM built-in classes. Before starting this section, we recommend that you read through this tutorial first: [Model Customization](https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PELLM Models\n",
    "\n",
    "In this section we introduce the PELLM model, which is a parameter-efficient language model that can be used in federated learning settings. They are designed to be compatible with the FATE-LLM framework to enable federated model tuning/training.\n",
    "\n",
    "PELLM models are located at federatedml.nn.model_zoo.pellm(federatedml/nn/model_zoo/pellm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert.py  bloom.py    distilbert.py  parameter_efficient_llm.py\n",
      "bart.py    chatglm.py  gpt2.py\t      roberta.py\n",
      "bert.py    deberta.py  llama.py\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../fate/python/fate_llm/model_zoo/pellm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can initialize your GPT2 model by loading the pretrained model from the model folder, or downloading the pretrained model from the Huggingface,\n",
    "here we initialize the GPT2 model with the Lora Adapter, we will introduce Adapters in the following sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly use adapters from the peft. See details for adapters on this page [Adapter Methods](https://huggingface.co/docs/peft/index#supported-methods) for more details. By specifying the adapter name and the adapter\n",
    "config dict we can insert adapters into our language models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**During the training process, all weights of the pretrained language model exclusive classifier head's weihgts will be frozen, and weights of adapters are traininable. Thus, FATE-LLM only train in the local training and aggregate adapters' weights and classifier head's weights(If has) in the fedederation process**\n",
    "\n",
    "Now available adapters are [Adapters Overview](https://huggingface.co/docs/peft/index) for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PELLM Model in FATE with CustModel\n",
    "\n",
    "In this [Model Customization](https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/pipeline/nn_tutorial/Homo-NN-Customize-Model.ipynb) tutorial, we demonstrate how to employ the t.nn.CustomModel class in fate_torch to parse a model's structure and submit it to a federated learning task. The CustomModel automatically imports the model class from the model_zoo and initializes the models with the parameters provided. Since these language models are built-in, we can directly use them in the CustomModel and easily add a classifier head to address the classification task at hand："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/data/projects/fate/env/python/venv/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component.nn import save_to_fate_llm\n",
    "fate_torch_hook(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate_llm model sigmoid.py\n",
    "\n",
    "import torch as t\n",
    "\n",
    "class Sigmoid(t.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sigmoid = t.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(x.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Federated Task\n",
    "Once you have successfully completed local testing, We can submit a task to FATE. Please notice that this tutorial is ran on a standalone version. **Please notice that in this tutorial we are using a standalone version, if you are using a cluster version, you need to bind the data with the corresponding name&namespace on each machine.**\n",
    "\n",
    "In this example we load pretrained weights for gpt2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224',\n",
    "    num_labels=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViTForImageClassification(\n",
      "  (vit): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (6): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (7): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (8): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (9): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (10): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (11): ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-01 15:02:01.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202312011502015721950\n",
      "\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:01.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[0mm2023-12-01 15:02:02.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-12-01 15:02:02.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:03.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:04.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:05.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[0mm2023-12-01 15:02:08.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-12-01 15:02:08.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:09.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:10.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:11.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:12.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:10\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:13.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:11\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:14.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:15.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[32m2023-12-01 15:02:16.217\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m101\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function '<module>', process 'MainProcess' (32584), thread 'MainThread' (140163725576000):\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"/data/projects/fate/env/python/miniconda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           │         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
      "           │         └ <code object <module> at 0x7f7a680b60e0, file \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel_laun...\n",
      "           └ <function _run_code at 0x7f7a6808d4c0>\n",
      "  File \"/data/projects/fate/env/python/miniconda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
      "         └ <code object <module> at 0x7f7a680b60e0, file \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel_laun...\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py'>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x7f7a63c97040>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7f7a68174520>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x7f7a63c97dc0>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f7a629d0d60>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7f7a68174520>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x7f7a65bcdf70>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f7a629d0d60>\n",
      "  File \"/data/projects/fate/env/python/miniconda/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x7f7a65bcfaf0>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/data/projects/fate/env/python/miniconda/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x7f7a65c1a790>\n",
      "    └ <Handle <TaskWakeupMethWrapper object at 0x7f79fa86c8e0>(<Future finis...bf0>, ...],))>)>\n",
      "  File \"/data/projects/fate/env/python/miniconda/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle <TaskWakeupMethWrapper object at 0x7f79fa86c8e0>(<Future finis...bf0>, ...],))>)>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle <TaskWakeupMethWrapper object at 0x7f79fa86c8e0>(<Future finis...bf0>, ...],))>)>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle <TaskWakeupMethWrapper object at 0x7f79fa86c8e0>(<Future finis...bf0>, ...],))>)>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x7f7a64378b80>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7f7a629dd400>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.sugar.frame.Frame object at 0x7f79fa6de720>, <zmq.sugar.frame.Frame object at 0x7f7a60191250>, <zmq.sugar.frame.Frame ...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7f7a629dd400>>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object Kernel.execute_request at 0x7f79fab07cc0>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x7f79fa035f40>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x7f7a63c86700>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7a629dd970>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': '8d42a18e-ae41-400b-b276-f3235949f0ad'}\n",
      "                             └ ('import torch as t\\nimport os\\nfrom pipeline import fate_torch_hook\\nfrom pipeline.component import HomoNN\\nfrom pipeline.co...\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x7f7a64f1be50>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7a629dd970>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x7f79fa04eac0>\n",
      "             └ <function _pseudo_sync_runner at 0x7f7a64f0b700>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x7f79fa04eac0>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/tmp/ipykernel_32584/1859623478.py'\n",
      "                       │    │             │        └ [<_ast.Import object at 0x7f7a60171490>, <_ast.Import object at 0x7f7a601515e0>, <_ast.ImportFrom object at 0x7f79fa1c9f10>, ...\n",
      "                       │    │             └ <_ast.Module object at 0x7f7a60171580>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7f7a64f1d160>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7a629dd970>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 7f7a60171fd0, execution_count=8 error_before_exec=None error_in_exec=None info=<ExecutionInfo obje...\n",
      "             │    │        └ <code object <module> at 0x7f79f9fb8870, file \"/tmp/ipykernel_32584/1859623478.py\", line 101>\n",
      "             │    └ <function InteractiveShell.run_code at 0x7f7a64f1d1f0>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7a629dd970>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': \"\\n    LoraConfig(\\n    task_type=TaskType.SEQ_CLS,\\n    inference_mode=False, r=8, lora_...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7a629dd970>\n",
      "         │         │    └ <property object at 0x7f7a64f0ad60>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f7a629dd970>\n",
      "         └ <code object <module> at 0x7f79f9fb8870, file \"/tmp/ipykernel_32584/1859623478.py\", line 101>\n",
      "\n",
      "> File \"\u001b[32m/tmp/ipykernel_32584/\u001b[0m\u001b[32m\u001b[1m1859623478.py\u001b[0m\", line \u001b[33m101\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1mpipeline\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mfit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│        └ \u001b[0m\u001b[36m\u001b[1m<function PipeLine.fit at 0x7f79fe013550>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<pipeline.backend.pipeline.PipeLine object at 0x7f79f9ff5a60>\u001b[0m\n",
      "\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/fate_client-1.11.2-py3.8.egg/pipeline/backend/pipeline.py\", line 585, in fit\n",
      "    self._fit_status = self._job_invoker.monitor_job_status(self._train_job_id,\n",
      "    │    │             │    │            │                  │    └ '202312011502015721950'\n",
      "    │    │             │    │            │                  └ <pipeline.backend.pipeline.PipeLine object at 0x7f79f9ff5a60>\n",
      "    │    │             │    │            └ <function JobInvoker.monitor_job_status at 0x7f79fe008940>\n",
      "    │    │             │    └ <pipeline.utils.invoker.job_submitter.JobInvoker object at 0x7f79f9ff5d90>\n",
      "    │    │             └ <pipeline.backend.pipeline.PipeLine object at 0x7f79f9ff5a60>\n",
      "    │    └ None\n",
      "    └ <pipeline.backend.pipeline.PipeLine object at 0x7f79f9ff5a60>\n",
      "  File \"/data/projects/fate/env/python/venv/lib/python3.8/site-packages/fate_client-1.11.2-py3.8.egg/pipeline/utils/invoker/job_submitter.py\", line 94, in monitor_job_status\n",
      "    raise ValueError(f\"Job is failed, please check out job {job_id} by fate board or fate_flow cli\")\n",
      "\n",
      "\u001b[31m\u001b[1mValueError\u001b[0m:\u001b[1m Job is failed, please check out job 202312011502015721950 by fate board or fate_flow cli\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Job is failed, please check out job 202312011502015721950 by fate board or fate_flow cli",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m pipeline\u001b[38;5;241m.\u001b[39madd_component(nn_component, data\u001b[38;5;241m=\u001b[39mData(train_data\u001b[38;5;241m=\u001b[39mreader_0\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdata))\n\u001b[1;32m     99\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m--> 101\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/projects/fate/env/python/venv/lib/python3.8/site-packages/loguru/_logger.py:1251\u001b[0m, in \u001b[0;36mLogger.catch.<locals>.Catcher.__call__.<locals>.catch_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcatch_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catcher:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m/data/projects/fate/env/python/venv/lib/python3.8/site-packages/fate_client-1.11.2-py3.8.egg/pipeline/backend/pipeline.py:585\u001b[0m, in \u001b[0;36mPipeLine.fit\u001b[0;34m(self, job_parameters, callback_func)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_board_url \u001b[38;5;241m=\u001b[39m detail_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboard_url\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_info \u001b[38;5;241m=\u001b[39m SimpleNamespace(model_id\u001b[38;5;241m=\u001b[39mdetail_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    583\u001b[0m                                    model_version\u001b[38;5;241m=\u001b[39mdetail_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_version\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job_invoker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonitor_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_job_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparty_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/projects/fate/env/python/venv/lib/python3.8/site-packages/fate_client-1.11.2-py3.8.egg/pipeline/utils/invoker/job_submitter.py:94\u001b[0m, in \u001b[0;36mJobInvoker.monitor_job_status\u001b[0;34m(self, job_id, role, party_id, previous_status)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StatusCode\u001b[38;5;241m.\u001b[39mSUCCESS\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m JobStatus\u001b[38;5;241m.\u001b[39mFAILED:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob is failed, please check out job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by fate board or fate_flow cli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m JobStatus\u001b[38;5;241m.\u001b[39mWAITING:\n\u001b[1;32m     97\u001b[0m     elapse_seconds \u001b[38;5;241m=\u001b[39m timedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "\u001b[0;31mValueError\u001b[0m: Job is failed, please check out job 202312011502015721950 by fate board or fate_flow cli"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import os\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader\n",
    "from pipeline.interface import Data\n",
    "from transformers import ViTConfig\n",
    "\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "\n",
    "import os\n",
    "fate_project_path = '/data/projects/fate'\n",
    "guest = 9999\n",
    "host = 9999\n",
    "\n",
    "pipeline = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest, host=host,\n",
    "                                                                            arbiter=host)\n",
    "data_0 = {\"name\": \"cifar10\", \"namespace\": \"experiment\"}\n",
    "data_path = fate_project_path + '/examples/data/cifar10/train'\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path)\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path)\n",
    "\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='guest', party_id=guest).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host).component_param(table=data_0)\n",
    "\n",
    "#reader_1 = Reader(name=\"reader_1\")\n",
    "#reader_1.get_party_instance(role='guest', party_id=guest).component_param(table=data_0)\n",
    "#reader_1.get_party_instance(role='host', party_id=host).component_param(table=data_0)\n",
    "## Add your pretriained model path here, will load model&tokenizer from this path\n",
    "\n",
    "\n",
    "## LoraConfig\n",
    "from peft import LoraConfig, TaskType\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "\"\"\"\n",
    "    LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1,\n",
    "    #target_modules=['c_attn']\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model_path = 'google/vit-base-patch16-224'\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(module_name='pellm.vit', class_name='vit', pretrained_path=model_path,\n",
    "                   peft_config=lora_config.to_dict(), peft_type=\"LoraConfig\", num_labels=1000,  pad_token_id=50256),\n",
    "    t.nn.CustModel(module_name='sigmoid', class_name='Sigmoid')\n",
    ")\n",
    "\n",
    "# DatasetParam\n",
    "dataset_param = DatasetParam(dataset_name='image') #\n",
    "#DatasetParam(dataset_name='nlp_tokenizer',text_max_length=128, tokenizer_name_or_path=model_path, \n",
    "#                             padding_side=\"left\", return_input_ids=False, pad_token='<|endoftext|>')\n",
    "# TrainerParam\n",
    "trainer_param = TrainerParam(trainer_name='fedavg_trainer', epochs=1, batch_size=8,\n",
    "                             data_loader_worker=8)\n",
    "\n",
    "\n",
    "nn_component = HomoNN(name='nn_0', model=model)\n",
    "\n",
    "# set parameter for client 1\n",
    "nn_component.get_party_instance(role='guest', party_id=guest).component_param(\n",
    "    loss=t.nn.BCELoss(),\n",
    "    optimizer = t.optim.Adam(lr=0.0001, eps=1e-8),\n",
    "    dataset=dataset_param,       \n",
    "    trainer=trainer_param,\n",
    "    torch_seed=100 \n",
    ")\n",
    "\n",
    "# set parameter for client 2\n",
    "nn_component.get_party_instance(role='host', party_id=host).component_param(\n",
    "    loss=t.nn.BCELoss(),\n",
    "    optimizer = t.optim.Adam(lr=0.0001, eps=1e-8),\n",
    "    dataset=dataset_param,       \n",
    "    trainer=trainer_param,\n",
    "    torch_seed=100 \n",
    ")\n",
    "\n",
    "# set parameter for server\n",
    "nn_component.get_party_instance(role='arbiter', party_id=guest).component_param(    \n",
    "    trainer=trainer_param\n",
    ")\n",
    "\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data))\n",
    "pipeline.compile()\n",
    "\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this script to submit the model, but submitting the model will take a long time to train and generate a long log, so we won't do it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with CUDA\n",
    "\n",
    "You can use GPU by setting the cuda parameter of the FedAVGTrainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_param = TrainerParam(trainer_name='fedavg_trainer', epochs=1, batch_size=8, \n",
    "                             data_loader_worker=8, cuda=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cuda parameter here accepts an integer value that corresponds to the index of the GPU you want to use for training. \n",
    "In the example above, the value is set to 0, which means that on every client the first available GPU in the system will be used. \n",
    "If you have multiple GPUs and would like to use a specific one, simply change the value of the cuda parameter to the appropriate index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
